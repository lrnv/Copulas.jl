<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started · Copulas.jl</title><meta name="title" content="Getting Started · Copulas.jl"/><meta property="og:title" content="Getting Started · Copulas.jl"/><meta property="twitter:title" content="Getting Started · Copulas.jl"/><meta name="description" content="Documentation for Copulas.jl."/><meta property="og:description" content="Documentation for Copulas.jl."/><meta property="twitter:description" content="Documentation for Copulas.jl."/><meta property="og:url" content="https://lrnv.github.io/Copulas.jl/getting_started/"/><meta property="twitter:url" content="https://lrnv.github.io/Copulas.jl/getting_started/"/><link rel="canonical" href="https://lrnv.github.io/Copulas.jl/getting_started/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.svg" alt="Copulas.jl logo"/><img class="docs-dark-only" src="../assets/logo-dark.svg" alt="Copulas.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">Copulas.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Manual</span><ul><li class="is-active"><a class="tocitem" href>Getting Started</a><ul class="internal"><li><a class="tocitem" href="#Multivariate-random-vectors"><span>Multivariate random vectors</span></a></li><li><a class="tocitem" href="#Copulas-and-Sklar&#39;s-Theorem"><span>Copulas and Sklar&#39;s Theorem</span></a></li><li><a class="tocitem" href="#Fitting-copulas-and-compound-distributions."><span>Fitting copulas and compound distributions.</span></a></li><li><a class="tocitem" href="#Going-further"><span>Going further</span></a></li></ul></li><li><a class="tocitem" href="../sklar/">Sklar&#39;s Distributions</a></li><li><a class="tocitem" href="../elliptical/generalities/">Elliptical Copulas</a></li><li><a class="tocitem" href="../archimedean/generalities/">Archimedean Copulas</a></li><li><a class="tocitem" href="../Liouville/">Liouville Copulas</a></li><li><a class="tocitem" href="../empirical/generalities/">Empirical Copulas</a></li><li><a class="tocitem" href="../dependence_measures/">Dependence measures</a></li></ul></li><li><span class="tocitem">Bestiary</span><ul><li><a class="tocitem" href="../elliptical/available_models/">Elliptical Copulas</a></li><li><a class="tocitem" href="../archimedean/available_models/">Archimedean Generators</a></li><li><a class="tocitem" href="../empirical/available_models/">Empirical Copulas</a></li><li><a class="tocitem" href="../miscellaneous/">Other Copulas</a></li><li><a class="tocitem" href="../transformations/">Transformed Copulas</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/lambda_viz/">Empirical Kendall function and Archimedean&#39;s λ function.</a></li><li><a class="tocitem" href="../examples/lossalae/">Loss-Alae fitting example.</a></li><li><a class="tocitem" href="../examples/fitting_sklar/">Fitting compound distributions</a></li><li><a class="tocitem" href="../examples/ifm1/">Influence of the method of estimation</a></li><li><a class="tocitem" href="../examples/turing/">Bayesian inference with <code>Turing.jl</code></a></li><li><a class="tocitem" href="../examples/other_usecases/">Other known use cases.</a></li></ul></li><li><a class="tocitem" href="../dev_roadmap/">Dev Roadmap</a></li><li><a class="tocitem" href="../idx/">Package Index</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Getting Started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting Started</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/lrnv/Copulas.jl/blob/main/docs/src/getting_started.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="Multivariate-random-vectors"><a class="docs-heading-anchor" href="#Multivariate-random-vectors">Multivariate random vectors</a><a id="Multivariate-random-vectors-1"></a><a class="docs-heading-anchor-permalink" href="#Multivariate-random-vectors" title="Permalink"></a></h2><p>This section gives some general definitions and tools about dependence structures, multivariate random vectors and copulas. Along this journey through the mathematical theory of copulas, we link to the rest of the documentation for more specific and detailed arguments on particular points, or simply to the technical documentation of the actual implementation.  The interested theoretical reader can take a look at the standard books on the subject [<a href="../references/#joe1997">1</a>–<a href="../references/#joe2014">4</a>] or more recently [<a href="../references/#mai2017">5</a>–<a href="../references/#grosser2021">8</a>]. </p><p>We start here by defining a few concepts about dependence structures and copulas. Consider a real valued random vector <span>$\bm X = \left(X_1,...,X_d\right): \Omega \to \mathbb R^d$</span>. The random variables <span>$X_1,...,X_d$</span> are called the marginals of the random vector <span>$\bm X$</span>. </p><div class="admonition is-info"><header class="admonition-header">Constructing random variables in Julia via `Distributions.jl`</header><div class="admonition-body"><p>Recall that you can construct random variables in Julia by the following code : </p><pre><code class="language-julia hljs">using Distributions
X₁ = Normal()       # A standard gaussian random variable
X₂ = Gamma(2,3)     # A Gamma random variable
X₃ = Pareto(1)      # A Pareto random variable with no variance.
X₄ = LogNormal(0,1) # A Lognormal random variable</code></pre><p>We refer to <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl&#39;s documentation</a> for more details on what you can do with these objects. We assume here that you are familiar with their API.</p></div></div><p>The probability distribution of the random vector <span>$\bm X$</span> can be characterized by its <em>distribution function</em> <span>$F$</span>: </p><p class="math-container">\[\begin{align*}
  F(\bm x) &amp;= \mathbb P\left(\bm X \le \bm x\right)\\
  &amp;= \mathbb P\left(\forall i \in \{1,...,d\},\; X_i \le x_i\right).
\end{align*}\]</p><p>For a function <span>$F$</span> to be the distribution function of some random vector, it should be <span>$d$</span>-increasing, right-continuous and left-limited.  For <span>$i \in \{1,...,d\}$</span>, the random variables <span>$X_1,...,X_d$</span>, called the marginals of the random vector, also have distribution functions denoted <span>$F_1,...,F_d$</span> and defined by : </p><p class="math-container">\[F_i(x_i) = F(+\infty,...,+\infty,x_i,+\infty,...,+\infty).\]</p><p>Note that the range <span>$\mathrm{Ran}(F)$</span> of a distribution function <span>$F$</span>, univariate or multivariate, is always contained in <span>$[0,1]$</span>. When the random vector or random variable is absolutely continuous with respect to (w.r.t.) the Lebesgue measure restricted to its domain, the range is exactly <span>$[0,1]$</span>. When the distribution is discrete with <span>$n$</span> atoms, the range is a finite set of <span>$n+1$</span> values in <span>$[0,1]$</span>.</p><h2 id="Copulas-and-Sklar&#39;s-Theorem"><a class="docs-heading-anchor" href="#Copulas-and-Sklar&#39;s-Theorem">Copulas and Sklar&#39;s Theorem</a><a id="Copulas-and-Sklar&#39;s-Theorem-1"></a><a class="docs-heading-anchor-permalink" href="#Copulas-and-Sklar&#39;s-Theorem" title="Permalink"></a></h2><p>There is a fundamental functional link between the function <span>$F$</span> and its marginals <span>$F_1,...,F_d$</span>. This link is expressed by the mean of <em>copulas</em>. </p><blockquote><p><strong>Definition (Copula) :</strong> A copula, usually denoted <span>$C$</span>, is the distribution function of a random vector with marginals that are all uniform on <span>$[0,1]$</span>, i.e.</p><p class="math-container">\[C_i(u) = u\mathbb 1_{u \in [0,1]} \text{ for all }i \in 1,...,d.\]</p></blockquote><div class="admonition is-info"><header class="admonition-header">Vocabulary</header><div class="admonition-body"><p>In this documentation but more largely in the literature, the term <em>Copula</em> refers both to the random vector and its distribution function. Usually, the distinction is clear from context. </p></div></div><p>You may define a copula object in Julia by simply calling its constructor: </p><pre><code class="language-julia hljs">using Copulas
d = 4 # The dimension of the model
θ = 7 # Parameter
C = ClaytonCopula(4,7) # A 4-dimensional clayton copula with parameter θ = 7.</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ClaytonCopula{4, Int64}(
G: Copulas.ClaytonGenerator{Int64}(7)
)
</code></pre><p>This object is a random vector, and behaves exactly as you would expect a random vector from <code>Distributions.jl</code> to behave: you may sample it with <code>rand(C,100)</code>, compute its pdf or cdf with <code>pdf(C,x)</code> and <code>cdf(C,x)</code>, etc:</p><pre><code class="language-julia hljs">u = rand(C,10)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×10 Matrix{Float64}:
 0.405528  0.929479  0.0490818  0.393049  …  0.193706  0.94575   0.592044
 0.489333  0.956795  0.0503915  0.445601     0.148652  0.913265  0.741376
 0.488967  0.994394  0.0363129  0.529284     0.147824  0.755305  0.618526
 0.408517  0.890059  0.0487929  0.638189     0.145528  0.855102  0.617727</code></pre><pre><code class="language-julia hljs">cdf(C,u)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">10-element Vector{Float64}:
 0.3561223493055228
 0.8420778060672544
 0.034793797165154676
 0.3685456269906675
 0.36609415237048604
 0.22665913327423448
 0.713893569931759
 0.12503629877663244
 0.7148121659600489
 0.5162292642875619</code></pre><p>One of the reasons that makes copulas so useful is discovered by Sklar [<a href="../references/#sklar1959">9</a>] in 1959:</p><blockquote><p><strong>Theorem (Sklar):</strong> For every random vector <span>$\bm X$</span>, there exists a copula <span>$C$</span> such that </p><p class="math-container">\[\forall \bm x\in \mathbb R^d, F(\bm x) = C(F_{1}(x_{1}),...,F_{d}(x_{d})).\]</p><p>The copula <span>$C$</span> is uniquely determined on <span>$\mathrm{Ran}(F_{1}) \times ... \times \mathrm{Ran}(F_{d})$</span>, where <span>$\mathrm{Ran}(F_i)$</span> denotes the range of the function <span>$F_i$</span>. In particular, if all marginals are absolutely continuous, <span>$C$</span> is unique.</p></blockquote><p>This result allows to decompose the distribution of <span>$\bm X$</span> into several components: the marginal distributions on one side, and the copula on the other side, which governs the dependence structure between the marginals. This object is central in our work, and therefore deserves a moment of attention. </p><blockquote><p><strong>Example (Independence):</strong> The function </p><p class="math-container">\[\Pi : \bm x \mapsto \prod_{i=1}^d x_i = \bm x^{\bm 1}\]</p><p>is a copula, corresponding to independent random vectors.</p></blockquote><p>The independence copula can be constructed using the <a href="../archimedean/available_models/#IndependentGenerator"><code>IndependentCopula(d)</code></a> syntax as follows: </p><pre><code class="language-julia hljs">Π = IndependentCopula(d) # A 4-variate independence structure.</code></pre><p>We leverage the Sklar theorem to construct multivariate random vectors from a copula-marginals specification. This can be used as follows: </p><pre><code class="language-julia hljs">MyDistribution = SklarDist(Π, (X₁,X₂,X₃,X₄))
MyOtherDistribution = SklarDist(C, (X₁,X₂,X₃,X₄))</code></pre><p>And the API is still the same: </p><pre><code class="language-julia hljs">rand(MyDistribution,10)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×10 Matrix{Float64}:
  1.39743   1.39032  -0.549776  -0.917544  …  0.84433   0.501131  -0.965732
  4.25873  14.8868    1.81859    1.20768      0.768173  7.48066    4.42986
  4.08872   1.72012   1.02174    1.27128      1.87471   1.21424    1.13591
 12.4426    1.38545   0.37922    2.60716      1.92694   0.286298   0.704866</code></pre><pre><code class="language-julia hljs">rand(MyOtherDistribution,10)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×10 Matrix{Float64}:
 -0.0770097  -1.10034   0.127587   1.79582  …  0.151928  0.0976101  0.0392866
  5.30925     2.39415   4.68561   18.4414      4.76126   4.70926    5.89048
  1.5698      1.22025   2.05016    3.91675     2.75677   2.15146    5.70803
  0.639794    0.356296  1.19899    3.13089     2.05624   1.05059    1.0122</code></pre><p>On the other hand, the <a href="../empirical/generalities/#Pseudo-observations"><code>pseudo()</code></a> function computes ranks, effectively using Sklar&#39;s theorem the other way around (from the marginal space to the unit hypercube).</p><div class="admonition is-info"><header class="admonition-header">Independent random vectors</header><div class="admonition-body"><p>Distributions.jl proposes the <a href="https://juliastats.org/Distributions.jl/stable/multivariate/#Product-distributions"><code>product_distribution</code></a> function to create those independent random vectors with given marginals. But you can already see that our approach generalizes to other dependence structres, and is thus much powerfull. </p></div></div><p>Copulas are bounded functions with values in [0,1] since they correspond to probabilities. But their range can be bounded more precisely:</p><blockquote><p><strong>Property (Fréchet-Hoeffding bounds [<a href="../references/#lux2017">10</a>]):</strong> For all <span>$\bm x \in [0,1]^d$</span>, every copula <span>$C$</span> satisfies : </p><p class="math-container">\[\langle \bm 1, \bm x - 1 + d^{-1}\rangle_{+} \le C(\bm x) \le \min \bm x,\]</p><p>where <span>$y_{+} = \max(0,y)$</span>.</p></blockquote><p>The function <span>$M : \bm x \mapsto \min\bm x$</span>, called the upper Fréchet-Hoeffding bound, is a copula. The function <span>$W : \bm x \mapsto \langle \bm 1, \bm x - 1 + d^{-1}\rangle_{+}$</span>, called the lower Fréchet-Hoeffding bound, is on the other hand a copula only when <span>$d=2$</span>.  These two copulas can be constructed through <a href="../archimedean/available_models/#MGenerator"><code>MCopula(d)</code></a> and <a href="../archimedean/available_models/#WGenerator"><code>WCopula(2)</code></a>. </p><p>The upper Fréchet-Hoeffding bound corresponds to the case of comonotone random vector: a random vector <span>$\bm X$</span> is said to be comonotone, i.e., to have copula <span>$M$</span>, when each of its marginals can be written as a non-decreasing transformation of the same random variable (say with <span>$\mathcal U\left([0,1]\right)$</span> distribution). This is a simple but important dependence structure. See e.g.,[<a href="../references/#kaas2002">11</a>, <a href="../references/#hua2017">12</a>] on this particular copula. Note that the implementation of their sampler was straightforward due to their particular shapes:</p><pre><code class="language-julia hljs">rand(MCopula(2),10) # sampled values are all equal, this is comonotony</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×10 Matrix{Float64}:
 0.732719  0.268221  0.522337  0.751976  …  0.61075  0.716798  0.420591
 0.732719  0.268221  0.522337  0.751976     0.61075  0.716798  0.420591</code></pre><pre><code class="language-julia hljs">u = rand(WCopula(2),10)
sum(u, dims=1) # sum is always equal to one, this is anticomonotony</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×10 Matrix{Float64}:
 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0</code></pre><p>Since copulas are distribution functions, like distribution functions of real-valued random variables and random vectors, there exists classical and useful parametric families of copulas. This is mostly the content of this package, and we refer to the rest of the documentation for more details on the models and their implementations. </p><h2 id="Fitting-copulas-and-compound-distributions."><a class="docs-heading-anchor" href="#Fitting-copulas-and-compound-distributions.">Fitting copulas and compound distributions.</a><a id="Fitting-copulas-and-compound-distributions.-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting-copulas-and-compound-distributions." title="Permalink"></a></h2><p><code>Distributions.jl</code>&#39;s API contains a <code>fit</code> function for random vectors and random variables. We propose an implementation of it for copulas and multivariate compound distributions (composed of a copula and some given marginals). It can be used as follows: </p><pre><code class="language-julia hljs">using Copulas, Distributions, Random
# Construct a given model:
X₁ = Gamma(2,3)
X₂ = Pareto()
X₃ = LogNormal(0,1)
C = ClaytonCopula(3,0.7) # A 3-variate Clayton Copula with θ = 0.7
D = SklarDist(C,(X₁,X₂,X₃)) # The final distribution

simu = rand(D,1000) # Generate a dataset

# You may estimate a copula using the `fit` function:
D̂ = fit(SklarDist{ClaytonCopula,Tuple{Gamma,Normal,LogNormal}}, simu)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">SklarDist{ClaytonCopula{3, Float64}, Tuple{Distributions.Gamma{Float64}, Distributions.Normal{Float64}, Distributions.LogNormal{Float64}}}(
C: ClaytonCopula{3, Float64}(
G: Copulas.ClaytonGenerator{Float64}(0.7870151319019776)
)

m: (Distributions.Gamma{Float64}(α=2.0461491553848323, θ=3.0166249574473403), Distributions.Normal{Float64}(μ=8.723645676811984, σ=53.97443392552653), Distributions.LogNormal{Float64}(μ=0.04896073233239987, σ=0.9950022735321237))
)
</code></pre><p>We see on the output that the parameters were correctly estimated from this sample. More details on the estimator, including, e.g., standard errors, may be obtained with more complicated estimation routines. For a Bayesian approach using  <code>Turing.jl</code>, see <a href="../examples/turing/#Bayesian-inference-with-Turing.jl">this example</a>.</p><div class="admonition is-info"><header class="admonition-header">Fitting procedures are not part of the API</header><div class="admonition-body"><p><a href="https://juliastats.org/Distributions.jl/stable/fit/#Distribution-Fitting"><code>Distributions.jl</code> documentation</a> states that: </p><blockquote><p>The fit function will choose a reasonable way to fit the distribution, which, in most cases, is maximum likelihood estimation.</p></blockquote><p>The results of this fitting function should then only be used as &quot;quick-and-dirty&quot; fits, since the fitting method is &quot;hidden&quot; to the user and might even change without breaking releases. We embrace this philosophy: from one copula to the other, the fitting method might not be the same. </p></div></div><h2 id="Going-further"><a class="docs-heading-anchor" href="#Going-further">Going further</a><a id="Going-further-1"></a><a class="docs-heading-anchor-permalink" href="#Going-further" title="Permalink"></a></h2><p>There are a lot of available copula families in the package, that can be regrouped into a few classes:</p><ul><li><a href="../elliptical/generalities/#elliptical_copulas_header">Elliptical Copulas</a>, including the Gaussian and Student cases. </li><li><a href="../archimedean/generalities/#archimedean_copulas_header">Archimedean Copulas</a>, leveraging their <a href="../archimedean/generalities/#archimedean_copulas_header">Archimedean Generators</a></li><li><a href="https://en.wikipedia.org/wiki/Copula_(probability_theory)#Fr%C3%A9chet%E2%80%93Hoeffding_copula_bounds">Fréchet-Hoeffding bounds</a>, </li><li><a href="../miscellaneous/#Other-Copulas">Other Copulas</a></li></ul><p>Each of these classes more-or-less correspond to an abstract type in our type hierarchy, and to a section of this documentation. </p><div class="citation noncanonical"><dl><dt>[1]</dt><dd><div>H. Joe. <em>Multivariate Models and Multivariate Dependence Concepts</em> (CRC press, 1997).</div></dd><dt>[2]</dt><dd><div>U. Cherubini, E. Luciano and W. Vecchiato. <em>Copula Methods in Finance</em> (John Wiley &amp; Sons, 2004).</div></dd><dt>[3]</dt><dd><div>R. B. Nelsen. <em>An Introduction to Copulas</em>. 2nd ed Edition, <em>Springer Series in Statistics</em> (Springer, New York, 2006).</div></dd><dt>[4]</dt><dd><div>H. Joe. <em>Dependence Modeling with Copulas</em> (CRC press, 2014).</div></dd><dt>[5]</dt><dd><div>J.-F. Mai, M. Scherer and C. Czado. <em>Simulating Copulas: Stochastic Models, Sampling Algorithms, and Applications</em>. 2nd edition Edition, Vol. 6 of <em>Series in Quantitative Finance</em> (World Scientific, New Jersey, 2017).</div></dd><dt>[6]</dt><dd><div>F. Durante and C. Sempi. <em>Principles of Copula Theory</em> (Chapman and Hall/CRC, 2015).</div></dd><dt>[7]</dt><dd><div>C. Czado. <em>Analyzing Dependent Data with Vine Copulas: A Practical Guide With R</em>. Vol. 222 of <em>Lecture Notes in Statistics</em> (Springer International Publishing, Cham, 2019).</div></dd><dt>[8]</dt><dd><div>J. Größer and O. Okhrin. <em>Copulae: An Overview and Recent Developments</em>. WIREs Computational Statistics (2021).</div></dd><dt>[9]</dt><dd><div>A. Sklar. <em>Fonctions de Repartition à n Dimension et Leurs Marges</em>. Université Paris <strong>8</strong>, 1–3 (1959).</div></dd><dt>[10]</dt><dd><div>T. Lux and A. Papapantoleon. <em>Improved Fréchet-Hoeffding Bounds on <span>$d$</span>-Copulas and Applications in Model-Free Finance</em>, arXiv:1602.08894 <a href="2017">math, q-fin</a>.</div></dd><dt>[11]</dt><dd><div>R. Kaas, J. Dhaene, D. Vyncke, M. J. Goovaerts and M. Denuit. <em>A Simple Geometric Proof That Comonotonic Risks Have the Convex-Largest Sum</em>. ASTIN Bulletin: The Journal of the IAA <strong>32</strong>, 71–80 (2002).</div></dd><dt>[12]</dt><dd><div>L. Hua and H. Joe. <em>Multivariate Dependence Modeling Based on Comonotonic Factors</em>. Journal of Multivariate Analysis <strong>155</strong>, 317–333 (2017).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../sklar/">Sklar&#39;s Distributions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Saturday 24 February 2024 07:51">Saturday 24 February 2024</span>. Using Julia version 1.10.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
